{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting snownlp\n",
      "  Downloading snownlp-0.12.3.tar.gz (37.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.6 MB 4.6 MB/s eta 0:00:01    |██▊                             | 3.3 MB 833 kB/s eta 0:00:42     |███▊                            | 4.4 MB 833 kB/s eta 0:00:40     |█████▋                          | 6.6 MB 9.8 MB/s eta 0:00:04     |█████████▏                      | 10.8 MB 9.8 MB/s eta 0:00:03     |██████████                      | 11.7 MB 9.8 MB/s eta 0:00:03     |███████████████▋                | 18.3 MB 1.6 MB/s eta 0:00:13     |██████████████████              | 21.1 MB 1.6 MB/s eta 0:00:11     |████████████████████            | 23.4 MB 5.4 MB/s eta 0:00:03     |██████████████████████▋         | 26.5 MB 5.4 MB/s eta 0:00:03     |██████████████████████████▉     | 31.5 MB 5.7 MB/s eta 0:00:02     |█████████████████████████████   | 34.0 MB 5.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: snownlp\n",
      "  Building wheel for snownlp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for snownlp: filename=snownlp-0.12.3-py3-none-any.whl size=37760957 sha256=e0a1f31d93f84168f60e8aaa42e7ae2a7b5108cf9c40caa4f2a65d16b7dc90ca\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/4a/7a/fe/a5747434679b22a95c93bcf9fa49a988f5d9be56366bdf6c79\n",
      "Successfully built snownlp\n",
      "Installing collected packages: snownlp\n",
      "Successfully installed snownlp-0.12.3\n",
      "WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "Collecting ggplot\n",
      "  Downloading ggplot-0.11.5-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 730 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from ggplot) (1.14.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ggplot) (1.17.5)\n",
      "Requirement already satisfied: statsmodels in /opt/conda/lib/python3.7/site-packages (from ggplot) (0.11.0)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from ggplot) (1.4.1)\n",
      "Requirement already satisfied: cycler in /opt/conda/lib/python3.7/site-packages (from ggplot) (0.10.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from ggplot) (0.25.3)\n",
      "Requirement already satisfied: patsy>=0.4 in /opt/conda/lib/python3.7/site-packages (from ggplot) (0.5.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from ggplot) (3.1.1)\n",
      "Collecting brewer2mpl\n",
      "  Downloading brewer2mpl-1.4.1-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas->ggplot) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas->ggplot) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ggplot) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ggplot) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->ggplot) (45.1.0.post20200119)\n",
      "Installing collected packages: brewer2mpl, ggplot\n",
      "Successfully installed brewer2mpl-1.4.1 ggplot-0.11.5\n"
     ]
    }
   ],
   "source": [
    "# install and import package\n",
    "!pip install  snownlp\n",
    "!pip install  ggplot\n",
    "import pandas\n",
    "import requests\n",
    "from snownlp import SnowNLP\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 下載微博武漢肺炎相關貼文\n",
    "def download_Cov_data(max):\n",
    "    articles = []\n",
    "    for i in range(1,max):\n",
    "        res = requests.get('https://m.weibo.cn/api/container/getIndex?containerid=231522type%3D1%26q%3D%23%E6%AD%A6%E6%B1%89%E8%82%BA%E7%82%8E%23&page_type=searchall&page={}'.format(i))\n",
    "        jd = res.json()\n",
    "        articles.extend([rec['mblog'] for rec in jd['data']['cards'] if rec.get('mblog')])\n",
    "\n",
    "    return pandas.DataFrame(articles)\n",
    "# 撈1~50頁資料\n",
    "df = download_Cov_data(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取出貼文資料\n",
    "def parseArticle(e):\n",
    "    soup = BeautifulSoup(e, 'html.parser')\n",
    "    return soup.text\n",
    "\n",
    "def parseQueryTime(e):\n",
    "    return e.split('&qtime=')[1].replace(\"&\",\"\")\n",
    "\n",
    "text_data=df['text'].map(parseArticle)\n",
    "query_time_data=df['itemid'].map(parseQueryTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進行每編貼文的情緒分析\n",
    "\n",
    "def getSentenment(e):\n",
    "    s = SnowNLP(e)\n",
    "    return s.sentiments\n",
    "\n",
    "sentiments_data=text_data.map(getSentenment)\n",
    "\n",
    "dict = {\n",
    "    \"查詢時間\":query_time_data,\n",
    "    \"貼文內容\": text_data,  \n",
    "     \"情緒分數\": sentiments_data\n",
    "       }\n",
    "\n",
    "select_df = pandas.DataFrame(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 輸出分析結果至terminal\n",
    "sorted_data= select_df.sort_values(by = '情緒分數',ascending = False)\n",
    "\n",
    "# 輸出分析結果至export_dataframe.csv檔\n",
    "# 情緒分數越大代表貼文內容越正面\n",
    "sorted_data['情緒分數']=sorted_data['情緒分數'].map(lambda x:format(x,'.4%'))\n",
    "sorted_data.to_csv (r'export_dataframe.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>查詢時間</th>\n",
       "      <th>貼文內容</th>\n",
       "      <th>情緒分數</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1580889478</td>\n",
       "      <td>#动物# #人与自然# #武汉肺炎# 动物、植物、人类等地球上一切生物都是大自然母亲的孩子关...</td>\n",
       "      <td>100.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1580889461</td>\n",
       "      <td>去年此刻，我在感受整个世界的热闹，人群与我无关，欢笑也是，阴霾笼罩了我一年，整整一年啊，这一...</td>\n",
       "      <td>100.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1580889466</td>\n",
       "      <td>【湖南发生H5N1禽流感‧4500只肉鸡发病死亡】2月1日，湖南省邵阳市双清区发生一起家禽H...</td>\n",
       "      <td>100.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1580889457</td>\n",
       "      <td>我真的是一个眼窝子比较浅的人，很容易被感动，这些天每次看到有关武汉的视频眼泪都是吧嗒吧嗒的留...</td>\n",
       "      <td>100.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1580889454</td>\n",
       "      <td>澳洲大火，中国疫情，东非蝗灾，开始想起来流浪地球的台词，“最初，没有人在意这场灾难，这不过是...</td>\n",
       "      <td>100.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1580889462</td>\n",
       "      <td>#武汉肺炎# #全民口罩行动# #体温检测# #逆向思维# 进社区要量测体温，但离开社区的却...</td>\n",
       "      <td>0.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1580889461</td>\n",
       "      <td>肺炎超话#武汉患者就医实情# @凤凰网视频 【患者亲述：#武汉邻市鄂州物资告急# 救护车不敢...</td>\n",
       "      <td>0.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1580889463</td>\n",
       "      <td>肺炎超话#比利时新型肺炎疫情# @梨视频 【#比利时确诊首例新冠病毒肺炎患者#：#从武汉撤侨...</td>\n",
       "      <td>0.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>1580889464</td>\n",
       "      <td>#武汉肺炎# #健康一春# 普通家庭如何做好居家消毒？在疾病流行期间，外出回家后，应及时用洗...</td>\n",
       "      <td>0.0000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>1580889474</td>\n",
       "      <td>【大陆男星狂扫16万个口罩　机场临时拜托「人肉带货」运回国】#胡海泉# #胡海泉人肉背口罩回...</td>\n",
       "      <td>0.0000%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           查詢時間                                               貼文內容       情緒分數\n",
       "454  1580889478  #动物# #人与自然# #武汉肺炎# 动物、植物、人类等地球上一切生物都是大自然母亲的孩子关...  100.0000%\n",
       "161  1580889461  去年此刻，我在感受整个世界的热闹，人群与我无关，欢笑也是，阴霾笼罩了我一年，整整一年啊，这一...  100.0000%\n",
       "255  1580889466  【湖南发生H5N1禽流感‧4500只肉鸡发病死亡】2月1日，湖南省邵阳市双清区发生一起家禽H...  100.0000%\n",
       "92   1580889457  我真的是一个眼窝子比较浅的人，很容易被感动，这些天每次看到有关武汉的视频眼泪都是吧嗒吧嗒的留...  100.0000%\n",
       "36   1580889454  澳洲大火，中国疫情，东非蝗灾，开始想起来流浪地球的台词，“最初，没有人在意这场灾难，这不过是...  100.0000%\n",
       "..          ...                                                ...        ...\n",
       "188  1580889462  #武汉肺炎# #全民口罩行动# #体温检测# #逆向思维# 进社区要量测体温，但离开社区的却...    0.0000%\n",
       "160  1580889461  肺炎超话#武汉患者就医实情# @凤凰网视频 【患者亲述：#武汉邻市鄂州物资告急# 救护车不敢...    0.0000%\n",
       "208  1580889463  肺炎超话#比利时新型肺炎疫情# @梨视频 【#比利时确诊首例新冠病毒肺炎患者#：#从武汉撤侨...    0.0000%\n",
       "221  1580889464  #武汉肺炎# #健康一春# 普通家庭如何做好居家消毒？在疾病流行期间，外出回家后，应及时用洗...    0.0000%\n",
       "400  1580889474  【大陆男星狂扫16万个口罩　机场临时拜托「人肉带货」运回国】#胡海泉# #胡海泉人肉背口罩回...    0.0000%\n",
       "\n",
       "[470 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
